{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Перевод размеченного датасета из русского языка (collection_3) на якутский.\n",
    "Сам датасет можно скачать по ссылке - http://files.deeppavlov.ai/deeppavlov_data/collection3_v2.tar.gz\n",
    "\n",
    "Для перевода необходимо получить ключ к API Яндекс-переводчика по этой ссылке - https://translate.yandex.ru/developers/keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from translater import translate_me\n",
    "from deeppavlov.models.tokenizers.ru_tokenizer import RussianTokenizer\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нужен ключ\n",
    "KEY = 'FIRST_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LEN = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RussianTokenizer(lowercase=False, alphas_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimeter = 'разделитель ||| араарааччы\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_unnecessary_lines(filename):\n",
    "    with open(filename) as f:\n",
    "        s = f.read()\n",
    "    s = s.replace('<DOCSTART>\\n\\n', '')\n",
    "    s = s.replace('\\n\\n\\n', '\\n\\n')\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_file(filename, add_delimiter=False, train_first_part=False, api_key=None):\n",
    "    with open(filename) as f:\n",
    "        s = f.read()\n",
    "    sentences = s.split('\\n\\n')\n",
    "    if train_first_part and 'train.txt' in filename:\n",
    "        sentences = sentences[:7000]\n",
    "    if not train_first_part and 'train.txt' in filename:\n",
    "        sentences = sentences[7000:]\n",
    "    corpus = ''\n",
    "    if add_delimiter:\n",
    "        corpus = delimeter\n",
    "    for sentence in sentences:\n",
    "        try:\n",
    "            words = [line.split()[0] for line in sentence.split('\\n')]\n",
    "            text = ' '.join(words)\n",
    "            entities = [line.split()[1] for line in sentence.split('\\n')]\n",
    "            if len(text) > MAX_SENTENCE_LEN: # Яндекс-переводчик почему-то не переводит длинные тексты\n",
    "                continue\n",
    "        except IndexError:\n",
    "            continue\n",
    "        tokens = tokenizer([translate_me(text, api_key)])[0]\n",
    "        corpus += ' '.join(words) + ' ||| ' + ' '.join(tokens) + '\\n'\n",
    "        \n",
    "    with open('data/corpus.txt', 'a') as f:\n",
    "        f.write(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перевод текстов\n",
    "Переводим тексты в формате - {русский текст} ||| {якутский текст}, как указано в https://github.com/clab/fast_align\n",
    "Между файлами будет разделитель - \"**разделитель ||| араарааччы**\"\n",
    "\n",
    "**Обратите внимание** на то, что АПИ сервиса позволяет в день перевести только 1.000.000 символов в день, в файле train около 1.200.000 символов, valid и train по 300.000. Поэтому нужно либо подождать день после перевода первой части train, либо получить дополнительный ключ с другого аккаунта.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_unnecessary_lines('data/collection_3/train.txt')\n",
    "delete_unnecessary_lines('data/collection_3/valid.txt')\n",
    "delete_unnecessary_lines('data/collection_3/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_file('data/train.txt', add_delimiter=False, train_first_part=True, api_key=KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = 'SECOND_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_file('data/collection_3/train.txt', add_delimiter=False, train_first_part=False, api_key=KEY)\n",
    "translate_file('data/collection_3/valid.txt', add_delimiter=True, train_first_part=False, api_key=KEY)\n",
    "translate_file('data/collection_3/test.txt', add_delimiter=True, train_first_part=False, api_key=KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка переведенного текста\n",
    "В нашей токенизации пунктуационные знаки считаются за отдельные токены, после перевода к словам могут прикрепиться символы '.', '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text, split_sign):\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        if word != split_sign:\n",
    "            words.append(word.split(split_sign)[0])\n",
    "        if word[-1] == split_sign:\n",
    "            words.append(split_sign)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpus = ''\n",
    "with open('data/corpus.txt') as f:\n",
    "    for line in f:\n",
    "        left, right = line.split(' ||| ')\n",
    "        left = left + ' ||| '\n",
    "        right = clear_text(right, split_sign='.')\n",
    "        right = clear_text(right, split_sign='-')\n",
    "        left = left + right + '\\n'\n",
    "        new_corpus += left\n",
    "        \n",
    "with open('data/cleaned_corpus.txt', 'w') as f:\n",
    "    f.write(new_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сопоставление слов с текстов русского языка на переведенные якутские.\n",
    "\n",
    "установить https://github.com/clab/fast_align\n",
    "\n",
    "1. Сопоставить с русского на якутский.\n",
    "```\n",
    "./fast_align -i data/cleaned_corpus.txt -d -o -v > data/forward.align\n",
    "```\n",
    "2. Сопоставить с якутского на русский.\n",
    "```\n",
    "./fast_align -i data/cleaned_corpus.txt -d -o -v -r > data/reverse.align\n",
    "```\n",
    "3. Применить эвристику с симметричными сопоставлениями для улучшения качества\n",
    "```\n",
    "./atools -i data/forward.align -j data/reverse.align -c data/grow-diag-final-and\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дополнение : Д . Медведев присвоил звания сотрудников полиции и переназначил 14 руководителей УВД , ГУВД и МВД по субъектам РФ . ||| Эбии : Д . Медведев полиция үлэһиттэрин аатын - суолун ылан РФ ИДьМ , ГУВД , ИДьМ субъектарыгар ИДьМ салайааччыларын ыҥырда .\n",
      "Дополнение Эбии\n",
      ": :\n",
      "Д Д\n",
      ". .\n",
      "Медведев Медведев\n",
      "присвоил полиция\n",
      "звания аатын\n",
      "сотрудников үлэһиттэрин\n",
      "полиции полиция\n",
      "и суолун\n",
      "и ылан\n",
      "переназначил РФ\n",
      "руководителей салайааччыларын\n",
      "УВД ИДьМ\n",
      ", ,\n",
      ", ,\n",
      "ГУВД ГУВД\n",
      "МВД ИДьМ\n",
      "по ИДьМ\n",
      "субъектам субъектарыгар\n",
      ". .\n",
      "\n",
      "\n",
      "Президент России Дмитрий Медведев присвоил звания сотрудников полиции и переназначил 14 руководителей управлений , главных управлений и министерств внутренних дел по субъектам РФ и федеральным округам . ||| Россия Президенэ Дмитрий Медведев полиция үлэһиттэрин аатын иҥэрдэ уонна РФ субъектарыгар уонна федеральнай уокуруктарга ис дьыала министерствотын 14 управлениеларыгар , кылаабынай управлениеларга уонна ис дьыала министерстволарыгар 14 салайааччыны анаата .\n",
      "Президент Президенэ\n",
      "России Россия\n",
      "Дмитрий Дмитрий\n",
      "Медведев Медведев\n",
      "присвоил полиция\n",
      "присвоил иҥэрдэ\n",
      "звания аатын\n",
      "сотрудников үлэһиттэрин\n",
      "полиции полиция\n",
      "и уонна\n",
      "переназначил РФ\n",
      "14 14\n",
      "управлений уокуруктарга\n",
      ", ,\n",
      "главных уонна\n",
      "управлений управлениеларга\n",
      "и уонна\n",
      "министерств уонна\n",
      "внутренних ис\n",
      "дел ис\n",
      "дел дьыала\n",
      "по дьыала\n",
      "субъектам субъектарыгар\n",
      "субъектам министерстволарыгар\n",
      "РФ РФ\n",
      "и уонна\n",
      "федеральным федеральнай\n",
      "округам уокуруктарга\n",
      ". .\n",
      "\n",
      "\n",
      "Об этом сообщили в пресс - службе Кремля . ||| Ол туһунан Кремль пресс - сулууспатыгар иһитиннэрдилэр .\n",
      "Об Ол\n",
      "этом туһунан\n",
      "пресс пресс\n",
      "- -\n",
      "службе сулууспатыгар\n",
      "службе иһитиннэрдилэр\n",
      "Кремля Кремль\n",
      ". .\n",
      "\n",
      "\n",
      "Также президент назначил генерал - майора полиции Юрия Прощалыкина начальником главного управления МВД РФ по Сибирскому федеральному округу , генерал - майора полиции Владимира Струкова - начальником управления на транспорте МВД РФ по Южному федеральному округу , генерал - майора полиции Андрея Таранова - начальником главного управления МВД РФ по Приволжскому федеральному округу . ||| Ону сэргэ президент Сибиирдээҕи федеральнай уокурукка РФ ИДьМ кылаабынай управлениетын начальнигынан , полиция генерал - майора Владимир Стручков - РФ Соҕуруу федеральнай уокурукка транспорга управлениетын начальнигынан , полиция генерал - майора Андрей Тарановы - РФ ИДьМ кылаабынай управлениетын начальнигынан анаата .\n",
      "Также Ону\n",
      "Также сэргэ\n",
      "президент президент\n",
      "назначил президент\n",
      "начальником начальнигынан\n",
      "главного кылаабынай\n",
      "управления управлениетын\n",
      "МВД ИДьМ\n",
      "РФ РФ\n",
      "федеральному федеральнай\n",
      "округу уокурукка\n",
      ", ,\n",
      "генерал генерал\n",
      "- -\n",
      "майора майора\n",
      "полиции полиция\n",
      "Владимира Владимир\n",
      "Струкова -\n",
      "- -\n",
      "начальником начальнигынан\n",
      "управления управлениетын\n",
      "на транспорга\n",
      "транспорте транспорга\n",
      "РФ РФ\n",
      "Южному Соҕуруу\n",
      "федеральному федеральнай\n",
      "округу уокурукка\n",
      ", ,\n",
      "генерал генерал\n",
      "- -\n",
      "майора майора\n",
      "полиции полиция\n",
      "Андрея Андрей\n",
      "Таранова Тарановы\n",
      "- -\n",
      "начальником начальнигынан\n",
      "главного кылаабынай\n",
      "управления управлениетын\n",
      "МВД ИДьМ\n",
      "РФ РФ\n",
      ". .\n",
      "\n",
      "\n",
      "Кроме того , полковник полиции Виктор Пауков назначен начальником управления внутренних дел по Центральному административному округу главного управления МВД РФ по Москве . ||| Ону таһынан полиция полковнига Виктор Паруков Москваҕа РФ ИДьМ кылаабынай управлениетын киин административнай уокурукка ис дьыала управлениетын начальнигынан ананна .\n",
      "Кроме Ону\n",
      "того таһынан\n",
      ", таһынан\n",
      "полковник полковнига\n",
      "полиции полиция\n",
      "Виктор Виктор\n",
      "Пауков Паруков\n",
      "назначен ананна\n",
      "начальником начальнигынан\n",
      "управления управлениетын\n",
      "внутренних ис\n",
      "дел ис\n",
      "дел дьыала\n",
      "по управлениетын\n",
      "Центральному киин\n",
      "административному административнай\n",
      "округу уокурукка\n",
      "главного кылаабынай\n",
      "управления управлениетын\n",
      "МВД ИДьМ\n",
      "РФ РФ\n",
      "Москве Москваҕа\n",
      ". .\n",
      "\n",
      "\n",
      "Премьер - министром Италии назначен Марио Монти ||| Италия премьер - миниистирэ Марио Монти ананна\n",
      "Премьер премьер\n",
      "- -\n",
      "министром миниистирэ\n",
      "Италии Италия\n",
      "назначен ананна\n",
      "Марио Марио\n",
      "Монти Монти\n",
      "\n",
      "\n",
      "Президент Италии Джорджо Наполитано назначил новым премьер - министром страны известного экономиста , бывшего еврокомиссара Марио Монти . ||| Италия Президенэ Джорджо бэлиитикэтин урукку еврокомиссара Марио Монти дойдутун саҥа премьер - миниистирин анаата .\n",
      "Президент Президенэ\n",
      "Италии Италия\n",
      "Джорджо Джорджо\n",
      "Наполитано Джорджо\n",
      "Наполитано бэлиитикэтин\n",
      "назначил анаата\n",
      "новым саҥа\n",
      "премьер премьер\n",
      "- -\n",
      "министром премьер\n",
      "страны дойдутун\n",
      "известного дойдутун\n",
      "экономиста дойдутун\n",
      "бывшего урукку\n",
      "еврокомиссара миниистирин\n",
      "Марио еврокомиссара\n",
      "Марио Марио\n",
      "Монти Монти\n",
      ". .\n",
      "\n",
      "\n",
      "Глава государства уже поручил ему сформировать новый кабинет министров , сообщает Reuters . ||| Государство баһылыга киниэхэ министрдэр саҥа кабинеттарын тэрийэргэ сорудахтаата , диэн иһитиннэрдэ .\n",
      "Глава баһылыга\n",
      "государства Государство\n",
      "ему киниэхэ\n",
      "сформировать тэрийэргэ\n",
      "новый саҥа\n",
      "кабинет сорудахтаата\n",
      "министров кабинеттарын\n",
      ", ,\n",
      "сообщает диэн\n",
      "Reuters иһитиннэрдэ\n",
      ". .\n",
      "\n",
      "\n",
      "М . Монти назначен на пост главы правительства после консультаций Д . Наполитано с представителями всех парламентских партий , групп и объединений , председателями обеих палат национального парламента , а также с предыдущими президентами республики и пожизненными сенаторами . ||| М . Манньыат Правительство баһылыгын консультация кэнниттэн Д . Бары парламент баартыйаларын , бөлөҕү уонна холбоһуктары бэрэстэбиитэллэрин , национальнай парламент икки палататын председателлэрин , ону сэргэ республика урукку Президеннэрин уонна олох - дьаһах сенатордарын кытта ыкса сибээстээхтэр .\n",
      "М М\n",
      ". .\n",
      "Монти М\n",
      "Монти Манньыат\n",
      "пост баһылыгын\n",
      "главы баһылыгын\n",
      "правительства Правительство\n",
      "после кэнниттэн\n",
      "консультаций консультация\n",
      "Д Д\n",
      ". .\n",
      "представителями холбоһуктары\n",
      "представителями бэрэстэбиитэллэрин\n",
      "парламентских парламент\n",
      ", ,\n",
      "групп ,\n",
      "и уонна\n",
      ", ,\n",
      "председателями председателлэрин\n",
      "обеих икки\n",
      "палат палататын\n",
      "национального национальнай\n",
      "парламента парламент\n",
      ", ,\n",
      "а ону\n",
      "также сэргэ\n",
      "с кытта\n",
      "с ыкса\n",
      "предыдущими сенатордарын\n",
      "президентами сенатордарын\n",
      "республики республика\n",
      "и уонна\n",
      "пожизненными сибээстээхтэр\n",
      "сенаторами сибээстээхтэр\n",
      ". .\n",
      "\n",
      "\n",
      "\" Наша страна должна спасти себя . ||| \" Биһиги дойдубут бэйэтин быыһаныахтаах .\n",
      "\" \"\n",
      "Наша Биһиги\n",
      "страна дойдубут\n",
      "должна дойдубут\n",
      "спасти быыһаныахтаах\n",
      "себя бэйэтин\n",
      ". .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Примеры сопоставлений\n",
    "with open('data/cleaned_corpus.txt') as f:\n",
    "    corpus = f.read().split('\\n')\n",
    "with open('data/final.align') as f:\n",
    "    mapping = f.read().split('\\n')\n",
    "    \n",
    "for i in range(10):\n",
    "    left, right = corpus[i].split(' ||| ')\n",
    "    left = left.split()\n",
    "    right = right.split()\n",
    "    print(corpus[i])\n",
    "    for ij in mapping[i].split():\n",
    "        ii, jj = list(map(int, ij.split('-')))\n",
    "        print(left[ii], right[jj])\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_translated_text(corpus):\n",
    "    corpus = corpus.strip()\n",
    "    sentences = corpus.split('\\n')\n",
    "    sentences = [sentence.split(' ||| ')[1].split() for sentence in sentences]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def extract_annotations(filename):\n",
    "    with open(filename) as f:\n",
    "        s = f.read().strip()\n",
    "    sentences = s.split('\\n\\n')\n",
    "    new_sentences = [[line.split()[0] for line in sentence.split('\\n')] for sentence in sentences]\n",
    "    annotations = [[line.split()[1] for line in sentence.split('\\n')] for sentence in sentences]\n",
    "    filter_length = [len(' '.join(sentence)) <= MAX_SENTENCE_LEN for sentence in new_sentences]\n",
    "    annotations = np.array(annotations)[filter_length].tolist()\n",
    "    return annotations\n",
    "\n",
    "\n",
    "def get_sentences_length(annotations):\n",
    "    len_sentences = [len(sentence) for sentence in annotations]\n",
    "    return len_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/cleaned_corpus.txt') as f:\n",
    "    corpus = f.read().strip()\n",
    "train = extract_translated_text(corpus.split(delimeter)[0])\n",
    "valid = extract_translated_text(corpus.split(delimeter)[1])\n",
    "test = extract_translated_text(corpus.split(delimeter)[2])\n",
    "\n",
    "train_annotations = extract_annotations('data/collection_3/train.txt')\n",
    "valid_annotations = extract_annotations('data/collection_3/valid.txt')\n",
    "test_annotations = extract_annotations('data/collection_3/test.txt')\n",
    "\n",
    "train_len_sentences = get_sentences_length(train_annotations)\n",
    "valid_len_sentences = get_sentences_length(valid_annotations)\n",
    "test_len_sentences = get_sentences_length(test_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_align_mapping(align, len_sentences):\n",
    "    align_mapping = [[[] for _ in range(len_sentences[i])] for i in range(len(align))]\n",
    "    for i_sentence, sentence in enumerate(align):\n",
    "        for mapping in sentence.split():\n",
    "            left, right = list(map(int, mapping.split('-')))\n",
    "            align_mapping[i_sentence][left].append(right)\n",
    "    return align_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем сопоставления\n",
    "with open('data/final.align') as f:\n",
    "    align = f.read().split('\\n')\n",
    "    \n",
    "train_align = align[:len(train)]\n",
    "valid_align = align[len(train) + 1:len(train) + len(valid) + 1]\n",
    "test_align = align[len(train) + len(valid) + 2:]\n",
    "test_align = test_align[:len(test)] # generated file has empty line at the end\n",
    "\n",
    "train_align_mapping = create_align_mapping(train_align, train_len_sentences)\n",
    "valid_align_mapping = create_align_mapping(valid_align, valid_len_sentences)\n",
    "test_align_mapping = create_align_mapping(test_align, test_len_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_translated_sentences(annotations, translated_sentences, align_mapping):\n",
    "    translated_annotations = [['O' for _ in sentence] for sentence in translated_sentences]\n",
    "    n_sentences = len(annotations)\n",
    "    for i_sen in range(n_sentences):        \n",
    "        for i_left, annotation in enumerate(annotations[i_sen]):\n",
    "            for i_right in align_mapping[i_sen][i_left]:\n",
    "                translated_annotations[i_sen][i_right] = annotations[i_sen][i_left]\n",
    "    return translated_annotations\n",
    "\n",
    "\n",
    "def correct_annotation(sentences, annotations):\n",
    "    new_annotations = copy.deepcopy(annotations)\n",
    "    begin = False\n",
    "    rem = False\n",
    "    for i_sen, words in enumerate(sentences):\n",
    "        for i in range(len(new_annotations[i_sen])):\n",
    "            if new_annotations[i_sen][i] == 'O':\n",
    "                begin = False\n",
    "                rem = False\n",
    "            if not begin and new_annotations[i_sen][i] != 'O':\n",
    "                new_annotations[i_sen][i] = 'B-' + new_annotations[i_sen][i].split('-')[1]\n",
    "            if new_annotations[i_sen][i][0] == 'B':\n",
    "                begin = True\n",
    "            if new_annotations[i_sen][i][0] == 'B' and words[i][0].isalpha() and words[i][0].islower():\n",
    "                rem = True\n",
    "            if new_annotations[i_sen][i][0] == 'B' and not (words[i][0].isalpha() and words[i][0].islower()):\n",
    "                rem = False\n",
    "            if rem:\n",
    "                new_annotations[i_sen][i] = 'O'\n",
    "    return new_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_translated_annotations = annotate_translated_sentences(train_annotations, train, train_align_mapping)\n",
    "valid_translated_annotations = annotate_translated_sentences(valid_annotations, valid, valid_align_mapping)\n",
    "test_translated_annotations = annotate_translated_sentences(test_annotations, test, test_align_mapping)\n",
    "\n",
    "train_translated_annotations = correct_annotation(train, train_translated_annotations)\n",
    "valid_translated_annotations = correct_annotation(valid, valid_translated_annotations)\n",
    "test_translated_annotations = correct_annotation(test, test_translated_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = [['\\t'.join(pair) for pair in  zip(train[i], train_translated_annotations[i])] for i in range(len(train))]\n",
    "new_valid = [['\\t'.join(pair) for pair in  zip(valid[i], valid_translated_annotations[i])] for i in range(len(valid))]\n",
    "new_test = [['\\t'.join(pair) for pair in  zip(test[i], test_translated_annotations[i])] for i in range(len(test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = '\\n\\n'.join(['\\n'.join(sentence) for sentence in new_train])\n",
    "new_valid = '\\n\\n'.join(['\\n'.join(sentence) for sentence in new_valid])\n",
    "new_test = '\\n\\n'.join(['\\n'.join(sentence) for sentence in new_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/collection_3/train_sa.txt', 'w') as f:\n",
    "    f.write(new_train)\n",
    "with open('data/collection_3/valid_sa.txt', 'w') as f:\n",
    "    f.write(new_valid)\n",
    "with open('data/collection_3/test_sa.txt', 'w') as f:\n",
    "    f.write(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
